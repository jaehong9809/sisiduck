import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnableBranch
from langchain_core.prompts import PromptTemplate
from langchain_community.utilities.serpapi import SerpAPIWrapper
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv
from googleapiclient.discovery import build
import feedparser
from urllib.parse import quote
from langchain.callbacks.base import BaseCallbackHandler
import asyncio

load_dotenv()

# 1ï¸âƒ£ OpenAI LLM ì„¤ì •

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)

# 2ï¸âƒ£ SerpAPI ì„¤ì •

# ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜

def fast_news_search(query: str) -> str:
    print("\nâš¡ ë¹ ë¥¸ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...\n")
    encoded_query = quote(query)  # ê³µë°± ë° í•œê¸€ ì¸ì½”ë”©
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    
    feed = feedparser.parse(url)
    results = []
    for entry in feed.entries[:3]:
        title = entry.title
        link = entry.link
        results.append(f"{title} - {link}")
    print(results)
    return "\n".join(results)


# ğŸ“º ìœ íŠœë¸Œ ê²€ìƒ‰ í•¨ìˆ˜

def youtube_search(query: str, max_results: int = 3) -> str:
    print("\nğŸš€ ìœ íŠœë¸Œ ê²€ìƒ‰ ì¤‘ (ë¹ ë¥´ê²Œ, ìµœëŒ€ ê°œìˆ˜ ì œí•œ!)\n")

    api_key = os.getenv("YOUTUBE_API_KEY")
    youtube = build("youtube", "v3", developerKey=api_key)

    request = youtube.search().list(
        q=query,
        part="snippet",
        type="video",
        maxResults=max_results
    )
    response = request.execute()

    # ğŸ‘‰ í•„ìš”í•œ ì •ë³´ë§Œ ì •ë¦¬í•´ì„œ ë°˜í™˜ (ì œëª© + ë§í¬)
    results = []
    for item in response.get("items", []):
        video_id = item["id"]["videoId"]
        title = item["snippet"]["title"]
        url = f"https://www.youtube.com/watch?v={video_id}"
        results.append(f"{title} - {url}")
    
    print(results)
    return "\n".join(results)

# 3ï¸âƒ£ ê¸ˆìœµ ìƒí’ˆ ê²€ìƒ‰ (Chroma)
embeddings = OpenAIEmbeddings()
vector_db = Chroma(persist_directory="finance_chroma_db", embedding_function=embeddings)
retriever = vector_db.as_retriever()

# 4ï¸âƒ£ ê¸°ëŠ¥ë³„ í”„ë¡¬í”„íŠ¸
idol_news_prompt = PromptTemplate.from_template(
    "ë‹¤ìŒì€ '{topic}'ì— ëŒ€í•œ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•´ì¤˜:\n\n{results}"
)

idol_video_prompt = PromptTemplate.from_template(
    "ë‹¤ìŒì€ '{topic}'ì— ëŒ€í•œ ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ì•Œë ¤ì¤˜:\n\n{results}"
)

finance_prompt = PromptTemplate.from_template(
    "ì‚¬ìš©ìê°€ ê´€ì‹¬ ìˆëŠ” '{interest}' ê´€ë ¨ ê¸ˆìœµ ìƒí’ˆì„ ì¶”ì²œí•´ì¤˜."
)

default_prompt = PromptTemplate.from_template(
    "ë„ˆëŠ” ì‹œë‹ˆì–´ ì¸µì—ê²Œ ì¹œì ˆí•˜ê²Œ ì¼ìƒëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆëŠ” ë•ìˆœì´ë¼ëŠ” ìºë¦­í„°ì•¼ ì‚¬ìš©ìì™€ ì¹œì ˆí•˜ê²Œ ì¼ìƒ ëŒ€í™” í•´ì¤˜: {input}"
)

# 5ï¸âƒ£ ì²´ì¸ êµ¬ì„±
idol_news_chain = idol_news_prompt | llm
idol_video_chain = idol_video_prompt | llm
finance_chain = finance_prompt | llm
default_chain = default_prompt | llm

# 6ï¸âƒ£ LCEL ê¸°ë°˜ ë¼ìš°íŒ…
router = RunnableBranch(
    
    (lambda x: x.get("type") == "video",
     lambda x: idol_video_chain.invoke({
         "topic": x["query"],
         "results": youtube_search(x["query"])
     })),

    (lambda x: x.get("type") == "news",
     lambda x: idol_news_chain.invoke({
         "topic": x["query"],
         "results": fast_news_search(x["query"])
     })),

    (lambda x: x.get("type") == "finance",
     lambda x: finance_chain.invoke({"interest": x["interest"]})),

    lambda x: default_chain.invoke({"input": x.get("input", "")})
)

def classify_query(user_input: str) -> dict:
    text = user_input.lower()
    if "ì˜ìƒ" in text or "ìœ íŠœë¸Œ" in text or "ë™ì˜ìƒ" in text:
        return {"type": "video", "query": user_input}
    elif "ë‰´ìŠ¤" in text or "ê¸°ì‚¬" in text or "ì†Œì‹" in text:
        return {"type": "news", "query": user_input}
    elif any(word in text for word in ["ì ê¸ˆ", "ì˜ˆê¸ˆ", "ê¸ˆìœµ", "ì´ì"]):
        return {"type": "finance", "interest": user_input}
    else:
        return {"type": "chat", "input": user_input}

# ì‹¤í–‰ í•¨ìˆ˜ (ì…ë ¥ê°’ì„ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬)
def question(query):
    print(f"ğŸ”¹ ì…ë ¥ê°’ í™•ì¸: {query}")  # ğŸš€ ë””ë²„ê¹…ìš© ì¶œë ¥
    keyword = classify_query(query)
    response = router.invoke(keyword)  # âœ… ìˆ˜ì •ëœ ì…ë ¥ê°’ í˜•ì‹
    return response.content