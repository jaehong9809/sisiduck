import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnableBranch
from langchain_core.prompts import PromptTemplate
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv
from googleapiclient.discovery import build
import feedparser
from urllib.parse import quote
from langchain.callbacks.base import BaseCallbackHandler
import asyncio

load_dotenv()

class SSECallbackHandler(BaseCallbackHandler):
    def __init__(self):
        self.queue = asyncio.Queue()
        self.buffer = ""

    async def on_llm_new_token(self, token: str, **kwargs):
        self.buffer += token
        # ë‹¨ì–´ë¡œ ìª¼ê°œê¸° (ê³µë°± í¬í•¨í•´ì„œ)
        while " " in self.buffer:
            word, self.buffer = self.buffer.split(" ", 1)
            await self.queue.put(word + " ")  # ê³µë°± í¬í•¨í•´ì„œ ë³´ë‚´ì¤Œ

    async def token_generator(self):
        while True:
            token = await self.queue.get()
            if token is None:
                break
            yield f"data: {token}\n\n"

    def finish(self):
        if self.buffer:
            self.queue.put_nowait(self.buffer)
            self.buffer = ""
        self.queue.put_nowait(None)

callback = SSECallbackHandler()

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5, streaming=True, callbacks=[callback])



def fast_news_search(query: str) -> str:
    print("\nâš¡ ë¹ ë¥¸ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...\n")
    encoded_query = quote(query)  # ê³µë°± ë° í•œê¸€ ì¸ì½”ë”©
    
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    
    feed = feedparser.parse(url)
    results = []
    for entry in feed.entries[:3]:
        title = entry.title
        link = entry.link
        results.append(f"{title} - {link}")
    print(results)
    return "\n".join(results)



def youtube_search(query: str, max_results: int = 3) -> str:
    print("\nğŸš€ ìœ íŠœë¸Œ ê²€ìƒ‰ ì¤‘ (ë¹ ë¥´ê²Œ, ìµœëŒ€ ê°œìˆ˜ ì œí•œ!)\n")

    api_key = os.getenv("YOUTUBE_API_KEY")
    
    youtube = build("youtube", "v3", developerKey=api_key)

    request = youtube.search().list(
        q=query,
        part="snippet",
        type="video",
        maxResults=max_results
    )
    response = request.execute()

    results = []
    
    for item in response.get("items", []):
        video_id = item["id"]["videoId"]
        title = item["snippet"]["title"]
        url = f"https://www.youtube.com/watch?v={video_id}"
        results.append(f"{title} - {url}")
    
    return "\n".join(results)

embeddings = OpenAIEmbeddings()
vector_db = Chroma(persist_directory="finance_chroma_db", embedding_function=embeddings)
retriever = vector_db.as_retriever()

idol_news_prompt = PromptTemplate.from_template(
    "ë„ˆëŠ” 'ë•ìˆœì´'ë¼ëŠ” ìºë¦­í„°ì•¼.\n"
    "ë•ìˆœì´ëŠ” ì‹œë‹ˆì–´ ë¶„ë“¤ê»˜ ì¹œì ˆí•˜ê²Œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•´.\n\n"
    "ë‹¤ìŒì€ '{topic}'ì— ëŒ€í•œ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì•¼.\n"
    "ì´ ë‚´ìš©ì„ ì‹œë‹ˆì–´ê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì„œ ì „ë‹¬í•´ì¤˜:\n\n"
    "{results}"
)

idol_video_prompt = PromptTemplate.from_template(
    "ë„ˆëŠ” 'ë•ìˆœì´'ë¼ëŠ” ìºë¦­í„°ì•¼.\n"
    "ë•ìˆœì´ëŠ” ì‹œë‹ˆì–´ ë¶„ë“¤ê»˜ ì¹œì ˆí•˜ê²Œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•´.\n\n"
    "ë‹¤ìŒì€ '{topic}'ì— ëŒ€í•œ ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ê²°ê³¼ì•¼.\n"
    "ì‹œë‹ˆì–´ ë¶„ë“¤ì—ê²Œ ìœ ìš©í•  ë§Œí•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ì„œ ì „ë‹¬í•´ì¤˜:\n\n"
    "{results}"
)

finance_prompt = PromptTemplate.from_template(
    "ë„ˆëŠ” 'ë•ìˆœì´'ë¼ëŠ” ìºë¦­í„°ì•¼.\n"
    "ë•ìˆœì´ëŠ” ì‹œë‹ˆì–´ ë¶„ë“¤ì—ê²Œ ê¸ˆìœµ ì •ë³´ë¥¼ ì¹œì ˆí•˜ê³  ì‰½ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ì—­í• ì„ í•´.\n\n"
    "ì‚¬ìš©ìê°€ ê´€ì‹¬ ìˆëŠ” '{interest}' ê´€ë ¨ ê¸ˆìœµ ìƒí’ˆì„\n"
    "ì‹œë‹ˆì–´ ëˆˆë†’ì´ì— ë§ê²Œ ì¶”ì²œí•´ì¤˜."
)

default_prompt = PromptTemplate.from_template(
    "ë„ˆëŠ” 'ë•ìˆœì´'ë¼ëŠ” ìºë¦­í„°ì•¼.\n"
    "ë•ìˆœì´ëŠ” ì‹œë‹ˆì–´ ë¶„ë“¤ê³¼ ì¹œì ˆí•˜ê³  ë”°ëœ»í•˜ê²Œ ì¼ìƒ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ì—­í• ì„ í•´.\n\n"
    "ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•´ ë‹¤ì •í•˜ê²Œ ë‹µí•´ì¤˜:\n"
    "{input}"
)


idol_news_chain = idol_news_prompt | llm
idol_video_chain = idol_video_prompt | llm
finance_chain = finance_prompt | llm
default_chain = default_prompt | llm

router = RunnableBranch(
    (lambda x: x.get("type") == "video",
     lambda x: idol_video_chain.invoke({
         "topic": x["query"],
         "results": youtube_search(x["query"])
     })),

    (lambda x: x.get("type") == "news",
     lambda x: idol_news_chain.invoke({
         "topic": x["query"],
         "results": fast_news_search(x["query"])
     })),

    (lambda x: x.get("type") == "finance",
     lambda x: finance_chain.invoke({"interest": x["interest"]})),

    lambda x: default_chain.invoke({"input": x.get("input", "")})
)

def classify_query(user_input: str) -> dict:
    text = user_input.lower()

    video_keywords = [
        "ì˜ìƒ", "ìœ íŠœë¸Œ", "ë™ì˜ìƒ", "ë¹„ë””ì˜¤", "ë³´ë‹¤", "ë³´ì—¬ì¤˜", "í´ë¦½", "ë…¹í™”", "ë®¤ì§ë¹„ë””ì˜¤"
    ]

    news_keywords = [
        "ë‰´ìŠ¤", "ê¸°ì‚¬", "ì†Œì‹", "ë³´ë„", "ì†ë³´", "í—¤ë“œë¼ì¸", "ì‹ ë¬¸", "ì´ìŠˆ"
    ]

    finance_keywords = [
        "ì ê¸ˆ", "ì˜ˆê¸ˆ", "ê¸ˆìœµ", "ì´ì", "ì€í–‰", "í†µì¥", "ìˆ˜ìµ", "ê¸ˆë¦¬", "ìƒí’ˆ", "íˆ¬ì", "ì¬í…Œí¬"
    ]

    # ì˜ìƒ ê´€ë ¨
    if any(word in text for word in video_keywords):
        return {"type": "video", "query": user_input}

    # ë‰´ìŠ¤ ê´€ë ¨
    elif any(word in text for word in news_keywords):
        return {"type": "news", "query": user_input}

    # ê¸ˆìœµ ê´€ë ¨
    elif any(word in text for word in finance_keywords):
        return {"type": "finance", "interest": user_input}

    # ê·¸ ì™¸ ì¼ë°˜ ëŒ€í™”
    else:
        return {"type": "chat", "input": user_input}



# ì‹¤í–‰ í•¨ìˆ˜ (ì…ë ¥ê°’ì„ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬)
def question(query):
    print(f"ğŸ”¹ ì…ë ¥ê°’ í™•ì¸: {query}")  # ğŸš€ ë””ë²„ê¹…ìš© ì¶œë ¥
    
    keyword = classify_query(query)
    
    response = router.invoke(keyword)  # âœ… ìˆ˜ì •ëœ ì…ë ¥ê°’ í˜•ì‹
    
    return response.content