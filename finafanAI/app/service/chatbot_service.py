from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_chroma import Chroma
from langchain.tools import Tool
from langchain_core.runnables import RunnableLambda
from langchain_community.utilities.serpapi import SerpAPIWrapper
from operator import itemgetter
from dotenv import load_dotenv
import os
import chromadb
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from youtubesearchpython import VideosSearch
from langchain_community.utilities.serpapi import SerpAPIWrapper
import json

load_dotenv()

# OpenAI ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-3.5-turbo" , temperature=0)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_function = OpenAIEmbeddings(model="text-embedding-ada-002")

# ChromaDB ì„¤ì •
chroma_client = chromadb.PersistentClient(path="./chroma_db")  # ì˜êµ¬ ì €ì¥

# ê¸°ì¡´ ChromaDB Collection ë¶ˆëŸ¬ì˜¤ê¸°
collection = chroma_client.get_or_create_collection(name="my_collection")

vectorstore = Chroma(
    client=chroma_client,
    collection_name="my_collection",
    embedding_function=embedding_function
)

# ğŸ” ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜
def search_chroma(query):
    results = vectorstore.similarity_search(query, k=3)  # ê°€ì¥ ìœ ì‚¬í•œ 3ê°œ ê²€ìƒ‰
    return "\n".join([doc.page_content for doc in results])

# ğŸŸ¢ YouTube ê²€ìƒ‰ ê¸°ëŠ¥
def search_youtube(query):
    search = VideosSearch(query, limit=1)
    results = search.result()

    if results and 'result' in results and results['result']:
        video = results['result'][0]
        video_url = video['link']
        return f"ì¶”ì²œ ì˜ìƒ: {video_url}"

    return "ê´€ë ¨ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ğŸŸ¢ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ê¸°ëŠ¥
news_search_tool = SerpAPIWrapper()
# ğŸŸ¢ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ê¸°ëŠ¥ (ë‰´ìŠ¤ ì œëª© + ë§í¬ ë°˜í™˜)
def search_news(query):
    raw_results = news_search_tool.run(query)  # SerpAPIì—ì„œ ë‰´ìŠ¤ ê²€ìƒ‰

    # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸ í›„ ì²˜ë¦¬
    if not isinstance(raw_results, list):
        return "ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    return raw_results  # ğŸš€ Observationì„ ê·¸ëŒ€ë¡œ ë°˜í™˜

# LangChain Tool ë“±ë¡
tools = [
    Tool(name="YouTube Search", func=search_youtube, description="ìœ íŠœë¸Œì—ì„œ ê´€ë ¨ ì˜ìƒì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."),
    Tool(name="News Search", func=search_news, description="ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤."),
    Tool(name="ChromaDB Vector Search", func=search_chroma, description="ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
]

# LangChain Agent ì„¤ì •
memory = ConversationBufferMemory(memory_key="chat_history")

prompt = PromptTemplate(
    template="""ë„ˆëŠ” í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. 
    ë„ˆì˜ ì—­í• ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ëŠ” ê²ƒì´ì•¼. 
    ì£¼ì–´ì§„ ë‰´ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•´ì¤˜.

    ì§ˆë¬¸: {question}
    """,
    input_variables=["question"],
)

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent="zero-shot-react-description",
    verbose=True,
    memory=memory,
    prompt = prompt,
)

# ğŸ”¹ Observationì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ë„ë¡ ì„¤ì •
agent_executor = AgentExecutor(
    agent=agent,
    handle_parsing_errors=True,  # ğŸš€ ì˜¤ë¥˜ ë°œìƒ ì‹œ Observationì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
    verbose=True
)

# ì‹¤í–‰ í•¨ìˆ˜ (ì…ë ¥ê°’ì„ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬)
def question(query):
    print(f"ğŸ”¹ ì…ë ¥ê°’ í™•ì¸: {query}")  # ğŸš€ ë””ë²„ê¹…ìš© ì¶œë ¥
    response = agent_executor.invoke({"input": query})  # âœ… ìˆ˜ì •ëœ ì…ë ¥ê°’ í˜•ì‹
    print(f"ğŸ”¹ ê²°ê³¼ í™•ì¸: {response}")  # ğŸš€ ë””ë²„ê¹…ìš© ì¶œë ¥
    return response["output"]