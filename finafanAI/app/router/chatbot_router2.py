# router/chatbot_router.py

from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from app.schemas.question import QuestionRequest
from app.service.callback_handler import SSECallbackHandler
from app.core.redis_utils import make_cache_key, get_cached_response, set_cached_response

from app.service.chain import hybrid_chain  # í•˜ì´ë¸Œë¦¬ë“œ ì²´ì¸: Agent + RAG

import asyncio

router = APIRouter()

@router.post("")
async def ask_question(request: QuestionRequest):
    question = request.question
    cache_key = make_cache_key(question)

    # âœ… 1. ìºì‹œ í™•ì¸
    cached = await get_cached_response(cache_key)
    if cached:
        async def stream_cached():
            for word in cached.split():
                yield f"data: {word} \n\n"
                await asyncio.sleep(0.015)
        return StreamingResponse(stream_cached(), media_type="text/event-stream")

    # âœ… 2. SSE ì½œë°± + ì‘ë‹µ ìˆ˜ì§‘
    callback = SSECallbackHandler()
    collected = []

    original_on_token = callback.on_llm_new_token

    # âœ… Final Answer ì´í›„ë§Œ ì‚¬ìš©ìì—ê²Œ ë³´ì´ê²Œ ì„¤ì •
    found_final = False

    async def capture_and_stream(token: str, **kwargs):
        nonlocal found_final
        collected.append(token)

        if not found_final and "Final Answer:" in "".join(collected):
            found_final = True

        if found_final:
            await original_on_token(token, **kwargs)

    callback.on_llm_new_token = capture_and_stream

    # âœ… ì²´ì¸ ì‹¤í–‰ í•¨ìˆ˜
    async def run_chain():
        try:
            await hybrid_chain.ainvoke(
                {"input": question},
                config={
                    "callbacks": [callback],
                    "tags": ["ë•ìˆœì´"],
                    "run_name": "HybridDuksuni"
                }
            )
        except Exception as e:
            print("âŒ Agent ì‹¤í–‰ ì˜¤ë¥˜:", e)
            await callback.queue.put("ì£„ì†¡í•´ìš”, ë•ìˆœì´ê°€ ì§€ê¸ˆì€ ëŒ€ë‹µí•˜ê¸° ì–´ë ¤ì›Œìš” ğŸ˜¢")
        finally:
            callback.finish()

    # âœ… ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸
    async def event_stream():
        await run_chain()

        # ìºì‹œì— Final Answer ê¸°ì¤€ ì €ì¥
        final_answer = "".join(collected).split("Final Answer:")[-1].strip()
        await set_cached_response(cache_key, final_answer)

        async for token in callback.token_generator():
            yield token

    return StreamingResponse(event_stream(), media_type="text/event-stream")
