from fastapi import APIRouter, Request
from fastapi.responses import StreamingResponse
from app.schemas.question import QuestionRequest
from app.service.v2.callback_handler import SSECallbackHandler
from app.core.redis_utils import make_cache_key, get_cached_response, set_cached_response
from app.service.v2.chain import needs_agent, get_agent_chain, get_chat_chain
import asyncio
import re

router = APIRouter()

@router.post("")
async def ask_question(request: QuestionRequest, req: Request):
    question = request.question
    question = re.sub(r'\s*ë•ìˆœ[ì´ê°€ì•„]?\s*', ' ', question).strip()
    user_id = req.headers.get("X-User-Id", "test")
    cache_key = make_cache_key(question)

    # âœ… 1. ìºì‹œ í™•ì¸
    cached = await get_cached_response(cache_key)
    if cached:
        async def stream_cached():
            for word in cached.split():
                yield f"data: {word} \n\n"
                await asyncio.sleep(0.01)

        return StreamingResponse(stream_cached(), media_type="text/event-stream")

    # âœ… 2. ì²´ì¸ ì‹¤í–‰ì„ ìœ„í•œ SSE ì½œë°± ì¤€ë¹„ (í† í° ìˆ˜ì§‘ìš©)
    callback = SSECallbackHandler()
    collected = []

    # âœ… ì½œë°± ì˜¤ë²„ë¼ì´ë”©: í† í° ìˆ˜ì§‘
    original_on_token = callback.on_llm_new_token

    async def capture_and_stream(token: str, **kwargs):
        collected.append(str(token))
        await original_on_token(token, **kwargs)

    callback.on_llm_new_token = capture_and_stream

    final_output = None

    async def run_chain():
        nonlocal final_output
        try:
            is_agent = await asyncio.to_thread(needs_agent, {"input": question})
            chain = get_agent_chain(callback) if is_agent else get_chat_chain(callback)

            result = await chain.ainvoke({"input": question, "user_id": user_id})

            final_output = result["output"]
            
        except Exception as e:
            print("âŒ ì²´ì¸ ì‹¤í–‰ ì˜¤ë¥˜:", e)
            final_output = "ì£„ì†¡í•´ìš”, ë•ìˆœì´ê°€ ì§€ê¸ˆì€ ëŒ€ë‹µí•˜ê¸° ì–´ë ¤ì›Œìš” ğŸ˜¢"
        finally:
            callback.finish()

    # âœ… 4. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (í›„ì²˜ë¦¬ í¬í•¨)
    async def event_stream():
        await run_chain()

        await set_cached_response(cache_key, final_output)

        for word in final_output.split():
            yield f"data: {word} \n\n"
            await asyncio.sleep(0.01)

    return StreamingResponse(event_stream(), media_type="text/event-stream")
